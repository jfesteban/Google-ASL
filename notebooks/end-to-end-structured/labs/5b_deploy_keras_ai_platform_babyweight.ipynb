{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 5b:  Deploy and predict with Keras model on Cloud AI Platform.\n",
    "\n",
    "**Learning Objectives**\n",
    "\n",
    "1. Setup up the environment\n",
    "1. Deploy trained Keras model to Cloud AI Platform\n",
    "1. Online predict from model on Cloud AI Platform\n",
    "1. Batch predict from model on Cloud AI Platform\n",
    "\n",
    "\n",
    "## Introduction \n",
    "In this notebook, we'll deploying our Keras model to Cloud AI Platform and creating predictions.\n",
    "\n",
    "We will set up the environment, deploy a trained Keras model to Cloud AI Platform, online predict from deployed model on Cloud AI Platform, and batch predict from deployed model on Cloud AI Platform.\n",
    "\n",
    "Each learning objective will correspond to a __#TODO__ in this student lab notebook -- try to complete this notebook first and then review the [solution notebook](../solutions/5b_deploy_keras_ai_platform_babyweight.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJ7ByvoXzpVI"
   },
   "source": [
    "## Set up environment variables and load necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Task #1: Set environment variables.\n",
    "\n",
    "Set environment variables so that we can use them throughout the entire lab. We will be using our project name for our bucket, so you only need to change your project and region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your current GCP Project Name is: qwiklabs-gcp-04-8722038efd75\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "PROJECT=$(gcloud config list project --format \"value(core.project)\")\n",
    "echo \"Your current GCP Project Name is: \"$PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these to try this notebook out\n",
    "PROJECT = \"qwiklabs-gcp-04-8722038efd75\"  # TODO: Replace with your PROJECT\n",
    "BUCKET = PROJECT  # defaults to PROJECT\n",
    "REGION = \"us-west1\"  # TODO: Replace with your REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"TFVERSION\"] = \"2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check our trained model files\n",
    "\n",
    "Let's check the directory structure of our outputs of our trained model in folder we exported the model to in our last [lab](../solutions/10_train_keras_ai_platform_babyweight.ipynb). We'll want to deploy the saved_model.pb within the timestamped directory as well as the variable values in the variables folder. Therefore, we need the path of the timestamped directory so that everything within it can be found by Cloud AI Platform's model deployment service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-04-8722038efd75/babyweight/trained_model/\n",
      "gs://qwiklabs-gcp-04-8722038efd75/babyweight/trained_model/1/\n",
      "gs://qwiklabs-gcp-04-8722038efd75/babyweight/trained_model/2/\n",
      "gs://qwiklabs-gcp-04-8722038efd75/babyweight/trained_model/20201210151302/\n",
      "gs://qwiklabs-gcp-04-8722038efd75/babyweight/trained_model/20201210151934/\n",
      "gs://qwiklabs-gcp-04-8722038efd75/babyweight/trained_model/3/\n",
      "gs://qwiklabs-gcp-04-8722038efd75/babyweight/trained_model/4/\n",
      "gs://qwiklabs-gcp-04-8722038efd75/babyweight/trained_model/5/\n",
      "gs://qwiklabs-gcp-04-8722038efd75/babyweight/trained_model/checkpoints/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil ls gs://${BUCKET}/babyweight/trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-04-8722038efd75/babyweight/trained_model/20201210151302/\n",
      "gs://qwiklabs-gcp-04-8722038efd75/babyweight/trained_model/20201210151302/saved_model.pb\n",
      "gs://qwiklabs-gcp-04-8722038efd75/babyweight/trained_model/20201210151302/assets/\n",
      "gs://qwiklabs-gcp-04-8722038efd75/babyweight/trained_model/20201210151302/variables/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://qwiklabs-gcp-04-8722038efd75/babyweight/trained_model/20201210151302/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-04-8722038efd75/babyweight/trained_model/20201210151934/\n",
      "gs://qwiklabs-gcp-04-8722038efd75/babyweight/trained_model/20201210151934/saved_model.pb\n",
      "gs://qwiklabs-gcp-04-8722038efd75/babyweight/trained_model/20201210151934/assets/\n",
      "gs://qwiklabs-gcp-04-8722038efd75/babyweight/trained_model/20201210151934/variables/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "MODEL_LOCATION=$(gsutil ls -ld -- gs://${BUCKET}/babyweight/trained_model/2* \\\n",
    "                 | tail -1)\n",
    "gsutil ls ${MODEL_LOCATION}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Task #2: Deploy trained model.\n",
    "\n",
    "Deploying the trained model to act as a REST web service is a simple gcloud call. Complete __#TODO__ by providing location of saved_model.pb file to Cloud AI Platoform model deployment service. The deployment will take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-west1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo ${REGION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting and deploying babyweight_10Dec ml_on_gcp from gs://qwiklabs-gcp-04-8722038efd75/babyweight/trained_model/20201210151302/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://ml.googleapis.com/]\n",
      "Created ml engine model [projects/qwiklabs-gcp-04-8722038efd75/models/babyweight_10Dec].\n",
      "Using endpoint [https://ml.googleapis.com/]\n",
      "Creating version (this might take a few minutes)......\n",
      ".....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"babyweight_10Dec\"\n",
    "MODEL_VERSION=\"ml_on_gcp\"\n",
    "MODEL_LOCATION=\"gs://qwiklabs-gcp-04-8722038efd75/babyweight/trained_model/20201210151302/\"\n",
    "echo \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION\"\n",
    "#gcloud ai-platform versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ai-platform models delete ${MODEL_NAME}\n",
    "gcloud ai-platform models create ${MODEL_NAME} --regions us-central1\n",
    "gcloud ai-platform versions create ${MODEL_VERSION} \\\n",
    "    --model=${MODEL_NAME} \\\n",
    "    --origin=${MODEL_LOCATION} \\\n",
    "    --runtime-version=2.1 \\\n",
    "    --python-version=3.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Task #3: Use model to make online prediction.\n",
    "\n",
    "Complete __#TODO__s for both the Python and gcloud Shell API methods of calling our deployed model on Cloud AI Platform for online prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python API\n",
    "\n",
    "We can use the Python API to send a JSON request to the endpoint of the service to make it predict a baby's weight. The order of the responses are the order of the instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"predictions\": [{\"weight\": [6.3127241134643555]}, {\"weight\": [6.494777679443359]}, {\"weight\": [4.891097545623779]}]}'\n"
     ]
    }
   ],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "import requests\n",
    "import json\n",
    "\n",
    "MODEL_NAME = \"babyweight_10Dec\"\n",
    "MODEL_VERSION = \"ml_on_gcp\"\n",
    "\n",
    "token = GoogleCredentials.get_application_default().get_access_token().access_token\n",
    "api = \"https://ml.googleapis.com/v1/projects/{}/models/{}/versions/{}:predict\" \\\n",
    "         .format(PROJECT, MODEL_NAME, MODEL_VERSION)\n",
    "headers = {\"Authorization\": \"Bearer \" + token }\n",
    "data = {\n",
    "  \"instances\": [\n",
    "    {\n",
    "      \"is_male\": \"True\",\n",
    "      \"mother_age\": 26.0,\n",
    "      \"plurality\": \"Single(1)\",\n",
    "      \"gestation_weeks\": 39\n",
    "    },\n",
    "    {\n",
    "      \"is_male\": \"False\",\n",
    "      \"mother_age\": 29.0,\n",
    "      \"plurality\": \"Single(1)\",\n",
    "      \"gestation_weeks\": 38\n",
    "    },\n",
    "    {\n",
    "      \"is_male\": \"True\",\n",
    "      \"mother_age\": 26.0,\n",
    "      \"plurality\": \"Triplets(3)\",\n",
    "      \"gestation_weeks\": 39\n",
    "    },\n",
    "  ]\n",
    "}\n",
    "response = requests.post(api, json=data, headers=headers)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions for the four instances were: 5.33, 6.09, 2.50, and 5.86 pounds respectively when I ran it (your results might be different)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gcloud shell API\n",
    "\n",
    "Instead we could use the gcloud shell API. Create a newline delimited JSON file with one instance per line and submit using gcloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inputs.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile inputs.json\n",
    "{\"is_male\": \"True\", \"mother_age\": 26.0, \"plurality\": \"Single(1)\", \"gestation_weeks\": 39}\n",
    "{\"is_male\": \"True\", \"mother_age\": 36.0, \"plurality\": \"Single(1)\", \"gestation_weeks\": 35}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now call `gcloud ai-platform predict` using the JSON we just created and point to our deployed `model` and `version`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEIGHT\n",
      "[6.3127241134643555]\n",
      "[6.281590938568115]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://ml.googleapis.com/]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ai-platform predict \\\n",
    "    --model=babyweight_10Dec \\\n",
    "    --json-instances=inputs.json \\\n",
    "    --version=ml_on_gcp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Task #4: Use model to make batch prediction.\n",
    "\n",
    "Batch prediction is commonly used when you have thousands to millions of predictions. It will create an actual Cloud AI Platform job for prediction. Complete __#TODO__s so we can call our deployed model on Cloud AI Platform for batch prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: babypred_201210_153901\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://inputs.json [Content-Type=application/json]...\n",
      "/ [1 files][  178.0 B/  178.0 B]                                                \n",
      "Operation completed over 1 objects/178.0 B.                                      \n",
      "CommandException: 1 files/objects could not be removed.\n",
      "Job [babypred_201210_153901] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe babypred_201210_153901\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs babypred_201210_153901\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "INPUT=gs://${BUCKET}/babyweight/batchpred/inputs.json\n",
    "OUTPUT=gs://${BUCKET}/babyweight/batchpred/outputs\n",
    "gsutil cp inputs.json $INPUT\n",
    "gsutil -m rm -rf $OUTPUT \n",
    "gcloud ai-platform jobs submit prediction babypred_$(date -u +%y%m%d_%H%M%S) \\\n",
    "    --data-format=TEXT \\\n",
    "    --region ${REGION} \\\n",
    "    --input-paths=$INPUT \\\n",
    "    --output-path=$OUTPUT \\\n",
    "    --model=babyweight_10Dec \\\n",
    "    --version=ml_on_gcp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Summary:\n",
    "In this lab, we set up the environment, deployed a trained Keras model to Cloud AI Platform, online predicted from deployed model on Cloud AI Platform, and batch predicted from deployed model on Cloud AI Platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2020 Google LLC\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "    https://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
